{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "zwfZGneCdQSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch torchvision torchsummary\n",
        "%pip install numpy\n",
        "%pip install matplotlib\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "a9FjTEzAdQ28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQaUBH8lmnnr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contents\n",
        "\n",
        "Today we'll attempt to create a number image generator through auto encoders. Here's the technique\n",
        "\n",
        "1. The model has 2 parts, an encoder and a decoder\n",
        "2. The encoder takes number image (mnist) and converts it into an embedding/encoding of specified size (output of encoder last layer). by passing it through multiple linear layers.\n",
        "3. The decoder then takes that encoding and attempts to re-create the original image\n",
        "4. During training, our cost function is the difference between generated image and original image. we'll use MSE Loss for this\n",
        "5. Once the training is complete, we'll create our own embeddings of specified size ourselves and run it through the decoder to generate images\n",
        "\n",
        "\n",
        "Note: In this notebook we'll limit ourselves to Linear Layers or BatchNorm's only (and activations). Which means NO CNN, attention, or anything fancier. For this reason, the performance might be questionable. What we wanna see is the model trying to capture the pattern?\n",
        "\n",
        "You need to know:\n",
        "\n",
        "1. **pytorch** (for impelementation)\n",
        "2. a bit of **torch dataloaders and datasets** (not necessary but helps understanding how we're loading data)\n",
        "3. A little bit of **matplotlib** (for result and training trajectory visualization)"
      ],
      "metadata": {
        "id": "gC2jmrtmiUm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                        transforms.RandomCrop(28, padding=4),\n",
        "                        transforms.ToTensor(),\n",
        "                    ])\n",
        "\n",
        "train_data = MNIST(root='./datasets', train=?, download=True, transform=?)\n",
        "train_loader = torch.utils.data.DataLoader(?, batch_size=?, shuffle=?)"
      ],
      "metadata": {
        "id": "b83RYTZueJCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoderGenerator(nn.Module):\n",
        "\n",
        "  def __init__(self, dim_z):\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    self.Encoder = nn.Sequential(\n",
        "      ?\n",
        "      .\n",
        "      .\n",
        "      .\n",
        "      ?\n",
        "      )\n",
        "\n",
        "\n",
        "    self.Decoder = nn.Sequential(\n",
        "      ?\n",
        "      .\n",
        "      .\n",
        "      .\n",
        "      ?\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    original_shape = x.shape\n",
        "    x = torch.flatten(?, start_dim=1)\n",
        "\n",
        "    z = ?\n",
        "    x = ?\n",
        "\n",
        "    x = x.view(original_shape)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "iEF-W-XZnB68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim_z = 128\n",
        "model = AutoEncoderGenerator(dim_z=?)"
      ],
      "metadata": {
        "id": "IFKJOAj5Pbdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (1, 28, 28), device='cpu')"
      ],
      "metadata": {
        "id": "YWBNQw3LtZd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 20\n",
        "lr = 1e-4\n",
        "optimizer = torch.optim.Adam(?, lr=lr)\n",
        "criterion = ?"
      ],
      "metadata": {
        "id": "tXbOcut4fJFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "\n",
        "for i in range(num_epochs):\n",
        "\n",
        "  epoch_weighted_loss = 0\n",
        "  for (X, _) in train_loader:\n",
        "\n",
        "    X = X.to(device)\n",
        "\n",
        "    Xhat = ?  # Xhat because we're trying to have the model regenerate what's fed to it (X)\n",
        "\n",
        "    optimizer.?()\n",
        "    loss = criterion(?, ?)\n",
        "    loss.?()\n",
        "    optimizer.?()\n",
        "\n",
        "    epoch_weighted_loss += loss.item()*len(X)\n",
        "\n",
        "  epoch_loss = epoch_weighted_loss/len(train_loader.dataset)\n",
        "\n",
        "  print(f'epoch {i}/{num_epochs}, loss = {epoch_loss}')\n",
        "\n",
        "  train_losses.append(epoch_loss)"
      ],
      "metadata": {
        "id": "CFXvYta-rxsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses)"
      ],
      "metadata": {
        "id": "XUwJuIZosq1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to display results\n",
        "def display_image_grid(images, num_rows, num_cols, title_text):\n",
        "\n",
        "    fig = plt.figure(figsize=(num_cols*3., num_rows*3.), )\n",
        "    grid = ImageGrid(fig, 111, nrows_ncols=(num_rows, num_cols), axes_pad=0.15)\n",
        "\n",
        "    for ax, im in zip(grid, images):\n",
        "        ax.imshow(im, cmap=\"gray\")\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(title_text, fontsize=20)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0wBaVZ0UvkOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will try some actual generation. We will sample the encodings randomly and then pass them through decoder\n",
        "\n",
        "rows, cols = 2, 7\n",
        "sample_encodings = (torch.rand(rows*cols, dim_z).to(device) - 0.5) * 2 # encoding space: [-1,1)\n",
        "with torch.no_grad():\n",
        "  generations = model.Decoder(sample_encodings).cpu()\n",
        "  generations = generations.reshape(-1, 28, 28, 1)\n",
        "display_image_grid(generations, rows, cols, \"generated_images\")"
      ],
      "metadata": {
        "id": "aO3WkbTiuQQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The images aren't too fancy but we can see it's trying to learn.\n",
        "In a few images we can also guess the number it's trying to generate"
      ],
      "metadata": {
        "id": "Zi16wGLUkWJa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MXtat3dgXs-9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}